---
title: LLM相关
number: 106
url: https://github.com/ysl2/.dotfiles/discussions/106
createdAt: 2025-01-29T03:52:50Z
lastEditedAt: 2025-06-27T17:31:55Z
updatedAt: 2025-06-27T17:32:17Z
author: ysl2
category: common
labels: []
countZH: 140
countEN: 330
filename: 2501-LLM相关
---

## 在线使用

> Ref: https://www.v2ex.com/t/1108382

中转API key提供方：
- https://luee.net/key ，速度快，但是感觉不是o3-mini
- https://siliconflow.cn ，可用deepseek。https://deepinfra.com


All in one：https://www.closechat.org/ ，速度快，并且是o3-mini，但是太贵
某宝还买了中转api，速度慢，只能o1-mini。直连key效果还行

前端：chatbox，桌面端/移动端都可用

## 本地部署

显卡：apple m3 silicon

后端：ollama

```
P ollama run deepseek-r1:32b
```

前端：gpt_academic

```
cp config.py config_private.py
python main.py
```

---

## Ollama安装

### 国内下载参考

> Ref: https://tianhao.tech/default/ollama-installation-guide-china.html

```bash
curl -fsSL https://ollama.com/install.sh -o ollama_install.sh
```

替换下载链接：

```bash
#!/bin/bash

# 文件路径
FILE="ollama_install.sh"

# 修改 URL
sed -i 's|https://ollama.com/download/ollama-linux-${ARCH}${VER_PARAM}|https://github.moeyy.xyz/https://github.com/ollama/ollama/releases/download/v0.3.4/ollama-linux-amd64|g' $FILE
sed -i 's|https://ollama.com/download/ollama-linux-amd64-rocm.tgz${VER_PARAM}|https://github.moeyy.xyz/https://github.com/ollama/ollama/releases/download/v0.3.4/ollama-linux-amd64-rocm.tgz|g' $FILE
```

### autodl下载参考

> Ref: https://blog.csdn.net/tirestay/article/details/139773544

```bash
source /etc/network_turbo
sudo apt update
sudo apt install systemd systemctl lshw
curl -fsSL https://ollama.com/install.sh | sh
# systemctl start ollama.service
# kill -9 [ollama process number]
http_proxy=127.0.0.1:7890 https_proxy=127.0.0.1:7890 OLLAMA_MODELS=/root/autodl-tmp/ollama ollama serve
http_proxy=127.0.0.1:7890 https_proxy=127.0.0.1:7890 OLLAMA_MODELS=/root/autodl-tmp/ollama ollama run deepseek-r1:70b
```

---

## GPT Academic安装

```bash
source /etc/network_turbo
http_proxy=127.0.0.1:7890 https_proxy=127.0.0.1:7890 git clone --depth=1 https://github.com/binary-husky/gpt_academic.git
cd gpt_academic
cp config.py config_private.py
vim config_private.py
conda init
source ~/.bashrc
conda create -n gptac_venv python=3.11
conda activate gptac_venv
python -m pip install -r requirements.txt
python main.py
```

---

## LLMs

chatbot arena

## Webs

chatgpt next web
lobe chat 一键本地部署（选择第二个模式，port mode）：https://github.com/lobehub/lobe-chat/blob/main/docker-compose/setup.sh

## Apps

chatbox
cherry studio
anythingllm

## RAG

RAGFlow
dify (non-free)

## Others

deepclaude